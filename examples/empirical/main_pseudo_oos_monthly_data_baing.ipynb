{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759ef2d1acaf242d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys,inspect\n",
    "# currentdir = os.path.dirname(os.path.abspath(inspect.getfile(inspect.currentframe())))\n",
    "# parentdir = os.path.dirname(currentdir)\n",
    "# parentdir = os.path.dirname(parentdir)\n",
    "parentdir = \"/Users/paoloandreini/Desktop/github_repo/DDFM_correction_paper/DDFM\"\n",
    "sys.path.insert(0,parentdir)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e12234f0ce487b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f8b6c20270380e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from examples.empirical.implementation.bai_ng_models import BaiNgModels\n",
    "import tqdm\n",
    "\n",
    "from pandas.tseries.offsets import MonthEnd\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7686aa4e0ba26dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date=pd.Timestamp(\"1990-01-01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2273c408536f2fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_m_all = pd.read_csv(os.path.join(parentdir, \"examples\", \"empirical\",\"data\",\"mdfred_snapshot_monthly.csv\"))\n",
    "transform_code_m = data_m_all.iloc[0,1:]\n",
    "transform_code_m = transform_code_m.astype(int)\n",
    "data_m = data_m_all.iloc[1:,:].set_index(\"sasdate\")\n",
    "data_m.index = pd.to_datetime(data_m.index)\n",
    "# convert to month end\n",
    "data_m.index = data_m.index + MonthEnd()\n",
    "data_m = data_m[data_m.index>=start_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7266fba0da4a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca_type:\n",
    "# classic PCA: PC and PC2\n",
    "# LarsPCA: LA - 5 variables, LAPC - 30 variables from X, LASPC 30 variables form X and X**2\n",
    "# targeted predictors: TPC- targeted preditors from X, and TPC2 - target targeted preditors from X adn X**2\n",
    "model_names = [\"PC\", \"TPC\", \"TSPC\", \"TPC2\", \"PC2\", \"LAPC\"]\n",
    "forecast={\"t1\":1, \"t6\":6, \"t12\": 12, \"t24\": 24}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15990e82abc07fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-estimate once a yaer\n",
    "months_oos = 12*19\n",
    "test_size = 12\n",
    "n_splits = int(months_oos/test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc8abb633dc7e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop on number of factors??\n",
    "publication_lag = 0 # should we keep it? It could avoid fowrdard looking bias\n",
    "y_all_targets = {}\n",
    "rmsfe_all = {}\n",
    "for target_i  in tqdm.tqdm(data_m.columns):\n",
    "    print(target_i)\n",
    "    y_pred_all_models = {}\n",
    "    rmsfe_models = {}\n",
    "    for fcst_name, fcst_lag in forecast.items():\n",
    "        y_pred_all_tmp = []\n",
    "        for name_i in [\"TPC\"]:#model_names:\n",
    "            # print(target_i, name_i, fcst_lag)\n",
    "            bai_ng_mdl = BaiNgModels(data_m, transform_code_m,\n",
    "                        staz=True, standardize=True, target_name=target_i,\n",
    "                        start_date=pd.Timestamp(\"1990-01-01\"),\n",
    "                        # models\n",
    "                        n_factors=5, # maybe try 5 and 10 as they do in the paper / or we shold use the same value we use\n",
    "                        model_name = name_i, lars_coef_number=None, target_freq=\"M\",\n",
    "                        thresh_tstat= 1.96, # we should use 1.25, 1.65, 2.56 in the paper\n",
    "                        n_targeted_predictors=None, lags_y = 5, lags_f = 7, # 7 is actually 6):\n",
    "                        )\n",
    "            \n",
    "            X_all = bai_ng_mdl.X_all.shift(fcst_lag+publication_lag).dropna(how=\"all\", axis=0).fillna(0) \n",
    "            y_all = bai_ng_mdl.y_all.loc[X_all.index].fillna(0) # bai_ng_mdl.y_all.shift(-fcst_lag).dropna() we can shift back the y or forward the X, same thing.\n",
    "            \n",
    "            target_mean = bai_ng_mdl.mean.loc[y_all.index]\n",
    "            target_std = bai_ng_mdl.sigma.loc[y_all.index]\n",
    "            target_name = bai_ng_mdl.target_name\n",
    "            tscv = TimeSeriesSplit(max_train_size=None, n_splits=n_splits, test_size=test_size)\n",
    "            tscv_index = tscv.split(X_all)\n",
    "\n",
    "            y_pred_all = []\n",
    "            for i, (train_index, test_index) in enumerate(tscv_index):\n",
    "                X = X_all.iloc[train_index]\n",
    "                y = y_all.iloc[train_index]\n",
    "\n",
    "                # fit model\n",
    "                bai_ng_mdl.fit(X, y)\n",
    "\n",
    "                # predict\n",
    "                # need to create X_reg\n",
    "                test_index_factors = list(train_index) + list(test_index)\n",
    "                X_pred = X_all.iloc[test_index_factors]\n",
    "                y_pred = y_all.iloc[test_index_factors]\n",
    "                y_pred = bai_ng_mdl.predict(X_pred, y_pred)\n",
    "                test_index_date = y_all.iloc[test_index].index\n",
    "                # print(test_index_date)\n",
    "                y_pred_all.append(y_pred.loc[test_index_date].map(np.real))\n",
    "            y_pred_all = pd.DataFrame(pd.concat(y_pred_all), columns = [name_i])\n",
    "            y_pred_all_tmp.append(y_pred_all)\n",
    "\n",
    "        y_hat_all_models = pd.concat(y_pred_all_tmp, axis=1)\n",
    "            \n",
    "        # compute RMSE\n",
    "        start_date = y_hat_all_models.index.min()\n",
    "        end_date = y_hat_all_models.index.max()\n",
    "\n",
    "        rmsfe = np.sqrt((((y_hat_all_models.T - y_all.loc[start_date:end_date]).T)**2).mean())\n",
    "        rmsfe_models[fcst_name]=rmsfe\n",
    "        \n",
    "        y_pred_all_models[fcst_name] = y_hat_all_models.dropna(how=\"all\", axis=0)\n",
    "        y_pred_all_models_df = pd.concat(y_pred_all_models)\n",
    "        y_pred_all_models_df.index.names = [\"step-ahead\", \"timestamp\"]\n",
    "    \n",
    "    rmsfe_all[target_i] = pd.concat(rmsfe_models)\n",
    "    y_all_targets[target_i] = y_pred_all_models_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f03575656175f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(rmsfe_all).to_csv(f\"{parentdir}/examples/empirical/results/rmsfe_publ_lag_0_all.csv\")\\\n",
    "pd.concat(y_all_targets).to_csv(f\"{parentdir}/examples/empirical/results/bai_ng_results_final_publ_lag0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb737d6b158251c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be80fb9600d624f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop on number of factors??\n",
    "# AR\n",
    "import statsmodels.api as sm\n",
    "publication_lag = 0 # should we keep it? It could avoid fowrdard looking bias\n",
    "y_all_targets_ar = {}\n",
    "rmsfe_all_ar = {}\n",
    "for target_i  in tqdm.tqdm(data_m.columns):\n",
    "    print(target_i)\n",
    "    y_pred_all_models = {}\n",
    "    rmsfe_models = {}\n",
    "    for fcst_name, fcst_lag in forecast.items():\n",
    "        y_pred_all_tmp = []\n",
    "        # print(target_i, name_i, fcst_lag)\n",
    "        bai_ng_mdl = BaiNgModels(data_m, transform_code_m,\n",
    "                    staz=True, standardize=True, target_name=target_i,\n",
    "                    start_date=pd.Timestamp(\"1990-01-01\"),\n",
    "                    # models\n",
    "                    n_factors=5, # maybe try 5 and 10 as they do in the paper / or we shold use the same value we use\n",
    "                    model_name = \"PC\",\n",
    "                    )\n",
    "            \n",
    "        X_all = bai_ng_mdl.y_all.shift(fcst_lag+publication_lag).dropna(how=\"all\", axis=0).fillna(0) \n",
    "        y_all = bai_ng_mdl.y_all.loc[X_all.index].fillna(0) # bai_ng_mdl.y_all.shift(-fcst_lag).dropna() we can shift back the y or forward the X, same thing.\n",
    "\n",
    "        target_name = bai_ng_mdl.target_name\n",
    "        tscv = TimeSeriesSplit(max_train_size=None, n_splits=n_splits, test_size=test_size)\n",
    "        tscv_index = tscv.split(X_all)\n",
    "\n",
    "        y_pred_all = []\n",
    "        for i, (train_index, test_index) in enumerate(tscv_index):\n",
    "            X = X_all.iloc[train_index]\n",
    "            y = y_all.iloc[train_index]\n",
    "            X_pred = X_all.iloc[test_index]\n",
    "\n",
    "            # fit model\n",
    "            model = sm.OLS(y, X).fit()\n",
    "\n",
    "            # predict\n",
    "            # need to create X_reg\n",
    "            y_pred = model.predict(X_pred)\n",
    "            # print(test_index_date)\n",
    "            y_pred_all.append(y_pred.map(np.real))\n",
    "        y_pred_all = pd.DataFrame(pd.concat(y_pred_all), columns = [target_i])\n",
    "        y_pred_all_tmp.append(y_pred_all)\n",
    "\n",
    "        y_hat_all_models = pd.concat(y_pred_all_tmp, axis=1)\n",
    "            \n",
    "        # compute RMSE\n",
    "        start_date = y_hat_all_models.index.min()\n",
    "        end_date = y_hat_all_models.index.max()\n",
    "\n",
    "        rmsfe = np.sqrt((((y_hat_all_models.T - y_all.loc[start_date:end_date]).T)**2).mean())\n",
    "        rmsfe_models[fcst_name]=rmsfe\n",
    "        \n",
    "        y_pred_all_models[fcst_name] = y_hat_all_models.dropna(how=\"all\", axis=0)\n",
    "        \n",
    "    y_pred_all_models_df = pd.concat(y_pred_all_models)\n",
    "    y_pred_all_models_df.index.names = [\"step-ahead\", \"timestamp\"]\n",
    "    rmsfe_all_ar[target_i] = pd.concat(rmsfe_models)\n",
    "    y_all_targets_ar[target_i] = y_pred_all_models_df.squeeze()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8177fff154c993",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(rmsfe_all_ar).to_csv(f\"{parentdir}/examples/empirical/results/rmsfe_ar1_all.csv\")\n",
    "pd.DataFrame(y_all_targets_ar).to_csv(f\"{parentdir}/examples/empirical/results/ar1_pred_all.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
